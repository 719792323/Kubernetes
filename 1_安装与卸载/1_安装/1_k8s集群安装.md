# 1.使用Kubeadm安装
## 1.1 集群机器要求
* master节点至少要2个cpu，否则报错
* 各节点必须关闭swap
* 各节点必须关闭防火墙
```text
error execution phase preflight: [preflight] Some fatal errors occurred:
[ERROR NumCPU]: the number of available CPUs 1 is less than the required 2
```
## 1.2 修改各机器/etc/hostname和/etc/hosts文件
必须设置

## 1.3 关闭防火墙与iptables
```shell
# centos
systemctl stop firewalld && systemctl disable firewalld 
systemctl stop iptables && systemctl disable iptables
# ubuntu
systemctl stop ufw.service
 systemctl disable ufw.service
```
## 1.4 关闭selinux
```shell
# 永久关闭
sed -i 's/enforcing/disabled/' /etc/selinux/config
# 临时关闭
setenforce 0 
```
## 1.5 关闭swap
```shell
# 永久关闭
sed -ri '/^[^#]*swap/s@^@#@' /etc/fstab
# 临时关闭
swapoff -a 
```
## 1.5 设置IPV4流量至iptables
有一些ipv4的流量不能走iptables链,会导致流量丢失，iptables链为linux内核的一个过滤器，每个流量都会经过他，然后再匹配是否可进入当前应用进程去处理
```shell
cat > /etc/sysctl.d/kubernetes.conf << EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF
# 生效
sysctl -p
modprobe br_netfilter
```
## 1.6 同步服务器时间
```shell
yum install chrony -y
systemctl start chronyd
systemctl enable chronyd
```
## 配置ipset与ipvsadm
```shell
yum -y install ipset ipvsadmin  
vim /etc/sysconfig/modules/ipvs.modules
#!/bin/bash 
modprobe -- ip_vs 
modprobe -- ip_vs_rr 
modprobe -- ip_vs_wrr 
modprobe -- ip_vs_sh 
modprobe -- nf_conntrack_ipv4  
chmod 755 /etc/sysconfig/modules/ipvs.modules && bash /etc/sysconfig/modules/ipvs.modules && lsmod | grep -e ip_vs -e nf_conntrack_ipv4
```
## 1.7 安装Docker
```shell
# 备份yum源
cd /etc/yum.repos.d ; mkdir backend; mv CentOS-Linux-* backend/
# centos7
wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
# 安装yum-config.yml.yml.yml-manager配置工具
yum -y install yum-utils
# 设置yum源
yum-config.yml.yml.yml-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
# 安装docker-ce版本
yum install -y docker-ce
# 启动
systemctl start docker
# 开机自启
systemctl enable docker
# 查看版本号
docker --version
# Docker镜像源设置
# 修改文件 /etc/docker/daemon.json，没有这个文件就创建
# 添加以下内容后，重启docker服务：
cat >/etc/docker/daemon.json<<EOF
{
 "exec-opts": ["native.cgroupdriver=systemd"],
 "registry-mirrors": ["https://mvrfhrpi.mirror.aliyuncs.com"]
 
}
EOF
# 加载
systemctl reload docker
# 查看
systemctl status docker containerd
```
## 1.8 设置k8s yum源
```shell
cat > /etc/yum.repos.d/kubernetes.repo << EOF
[k8s]
name=k8s
enabled=1
gpgcheck=0
baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
```
## 1.9 安装软件
```shell
yum install --setopt=obsoletes=0 kubeadm-1.17.4-0 kubelet-1.17.4-0 kubectl-1.17.4-0 -y
kubeadm images list
#将kubeadm config.yml images list输出的需要的镜像，存入images变量
images=(
k8s.gcr.io/kube-apiserver:v1.17.17
k8s.gcr.io/kube-controller-manager:v1.17.17
k8s.gcr.io/kube-scheduler:v1.17.17
k8s.gcr.io/kube-proxy:v1.17.17
k8s.gcr.io/pause:3.1
k8s.gcr.io/etcd:3.4.3-0
k8s.gcr.io/coredns:1.6.5
)
for imageName in ${images[@]}; 
do
  docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName  
  docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName 
  docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName 
done
```
将一个集群已有的镜像导出供给另外一个集群使用
> 导出脚本
```shell
# 保存镜像
# docker save -o <目标文件名.tar> <镜像名称:版本>
# 导入镜像
# docker load -i <tar文件名.tar>

#!/bin/bash

# 定义保存镜像的目录和tar文件名
output_directory="docker_images"
tar_file="docker_images.tar"

# 创建保存镜像的目录
mkdir -p "$output_directory"

# 镜像列表
images=(
  "k8s.gcr.io/metrics-server/metrics-server:v0.5.2"
  "k8s.gcr.io/kube-proxy:v1.17.4"
  "k8s.gcr.io/kube-controller-manager:v1.17.4"
  "k8s.gcr.io/kube-apiserver:v1.17.4"
  "k8s.gcr.io/kube-scheduler:v1.17.4"
  "k8s.gcr.io/coredns:1.6.5"
  "k8s.gcr.io/etcd:3.4.3-0"
  "k8s.gcr.io/pause:3.1"
)

# 保存镜像为tar文件
for image in "${images[@]}"; do
  echo "Saving image: $image"
  docker save -o "$output_directory/${image//\//_}.tar" "$image"
done

# 创建一个包含所有tar文件的压缩文件
tar -cf "$output_directory/$tar_file" "$output_directory"/*.tar

echo "All images saved to $output_directory/$tar_file"
```
> 导入脚本
```shell
tar -xf docker_images_k8s_1.17.tar
for tar_file in docker_images/*.tar; do
  echo "Loading image: $tar_file"
  docker load -i "$tar_file"
done
docker images
```


## 1.10 初始化集群
```shell
# master运行
# 注意修改下面命令的ip地址
kubeadm reset -f
rm -f /etc/kubernetes/kubelet.conf && rm -f /etc/kubernetes/pki/ca.crt
rm -rf ~/.kube/  /etc/kubernetes/* var/lib/etcd/* 
kubeadm init --apiserver-advertise-address=192.168.0.44  --kubernetes-version v1.17.4 --service-cidr=10.96.0.0/12 --pod-network-cidr=10.244.0.0/16
# 成功后 master运行
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config.yml
sudo chown $(id -u):$(id -g) $HOME/.kube/config.yml
# worker运行
kubeadm join xx
```
## 1.11 安装网络插件
```shell
kubectl apply -f kube-flannel.yml
# 如果kube-flannel安装不好，可以适用calico
注意，1.17的集群对应3.14
curl https://docs.projectcalico.org/v3.14/manifests/calico.yaml -O
kubectl apply -f calico.yaml
注意calico.yml需要设置网卡为本机对应的物理网卡,如下interface=enp3s0
            - name: IP_AUTODETECTION_METHOD
              value: "interface=enp3s0"
```

[删除网络插件](https://blog.csdn.net/weixin_43702146/article/details/127916984)

# 2.使用KuboardSpray安装

[教程地址](https://www.kuboard.cn/install/install-k8s.html#kuboard-spray)

# ubuntu安装k8s
[教程地址](https://blog.csdn.net/qq_40279964/article/details/125429233)

```shell
# 安装docker所需的工具（安装最新版即可）
apt-get update
apt-get install docker.io -y
# 设置开机启动并启动docker  
sudo systemctl start docker
sudo systemctl enable docker

# 禁用交换分区(在旧版的 k8s 中 kubelet 都要求关闭 swapoff ，但最新版的 kubelet 其实已经支持 swap ，因此这一步其实可以不做。)
swapoff -a
# 永久禁用，打开/etc/fstab注释掉swap那一行。  
sudo vim /etc/fstab
# 修改内核参数(首先确认你的系统已经加载了 br_netfilter 模块，默认是没有该模块的，需要你先安装 bridge-utils)
apt-get install -y bridge-utils
modprobe br_netfilter
lsmod | grep br_netfilter
# 如果报错找不到包，需要先更新 apt-get update -y

# 安装基础环境
apt-get install -y ca-certificates curl software-properties-common apt-transport-https curl
curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add -
# 执行配置k8s阿里云源  
vim /etc/apt/sources.list.d/kubernetes.list
#加入以下内容
deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main
# 执行更新
apt-get update -y
# 安装kubeadm、kubectl、kubelet  
apt-get install -y kubelet=1.23.1-00 kubeadm=1.23.1-00 kubectl=1.23.1-00
# 阻止自动更新(apt upgrade时忽略)。所以更新的时候先unhold，更新完再hold。
apt-mark hold kubelet kubeadm kubectl

#从国内镜像拉取
docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.23.8
docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.23.8
docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.23.8
docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.23.8
docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6
docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.1-0
docker pull coredns/coredns:1.8.6


#将拉取下来的images重命名为kubeadm config所需的镜像名字
docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.23.8 k8s.gcr.io/kube-apiserver:v1.23.8
docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.23.8 k8s.gcr.io/kube-controller-manager:v1.23.8
docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.23.8 k8s.gcr.io/kube-scheduler:v1.23.8
docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.23.8 k8s.gcr.io/kube-proxy:v1.23.8
docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6 k8s.gcr.io/pause:3.6
docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.1-0 k8s.gcr.io/etcd:3.5.1-0
docker tag coredns/coredns:1.8.6 k8s.gcr.io/coredns/coredns:v1.8.6

# 注意修改对应内容
kubeadm init --config kubeadm-config.yaml

# 记住node加入集群的命令 上面kubeadm init执行成功后会返回给你node节点加入集群的命令，等会要在node节点上执行，需要保存下来，如果忘记了，可以使用如下命令获取。
kubeadm token create --print-join-command

```

